{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering for Implicit Feedback Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function for squared error with regularization\n",
    "\n",
    "Across all x (users) and y (items), find the values of u and i that minimize the summation below:\n",
    "\n",
    "$\\underset{x,y}min\\underset{u,i}\\sum \n",
    "c_{ui} (p_{ui} - x_u^Ty_i)^2 + \\lambda\n",
    "(\\underset u \\sum \\parallel x_u \\parallel ^2\n",
    "+\\underset u \\sum \\parallel y_i \\parallel ^2)$\n",
    "\n",
    "##### Where:\n",
    "\n",
    "$x_u$ is user vector,\n",
    "$y_i$ is item vector.\n",
    "\n",
    "$p_{ui} = 1$ if interaction, \n",
    "$p_{ui} = 0$ if no interaction.\n",
    "\n",
    "$c_{ui} = 1 + \\alpha * r_{ui}$, where\n",
    "$r_{ui}$ = # of interactions for a user-item pair, and $\\alpha$ determines our confidence levels.\n",
    "\n",
    "$\\lambda$ is regularization term.\n",
    "\n",
    "#### Explanation of cost function\n",
    "\n",
    "We take the squared error of our prediction and \n",
    "multiply by the confidence, and regularize our $x$ and $y$ vectors with $\\lambda$ to penalize overfitting. (larger values or smaller values?)\n",
    "\n",
    "$\\alpha$ allows us to influence our confidence levels. Clearly, our confidence increases when a producer samples the same artist multiple times, but by how much? $\\alpha$ determines how important multiple samples are.\n",
    "\n",
    "We add 1 so that non-interactions are not lost during the cost calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Algorithm\n",
    "\n",
    "However, we can't use the cost function above because of the size of the dataset. (m * n terms)\n",
    "\n",
    "Therefore we modify the cost function to Alternating Least Squares, which works by holding either user vectors or item vectors constant and calculating the global minimum, then alternating to the other vector.\n",
    "\n",
    "#### Compute user factors\n",
    "\n",
    "$x_u = (Y^T C^u Y + \\lambda I)^{-1}  Y^T C^u p(u)$\n",
    "\n",
    "##### Where:\n",
    "\n",
    "$Y$ is $n * f$ matrix of item-factors. \n",
    "\n",
    "$C^u$ is a $n*n$ diagonal matrix for user $u$ where $C^u_{ii} = c_{ui}$. Each $C^u$ is our confidence matrix for $n$ items for $u$ user.\n",
    "\n",
    "$p(u)$ is vector of preferences for user $u$.\n",
    "\n",
    "\n",
    "#### Recompute item factors\n",
    "\n",
    "$y_i = (X^TC^iX + \\lambda I)^-1 X^TC^ip(i)$\n",
    "\n",
    "##### Where:\n",
    "$X$ = $m * f$ matrix  of user_factors. \n",
    "\n",
    "$C^i$ is $m * m$ diagonal matrix for each item $i$ where $C_{uu}^i = c_{ui}$\n",
    "\n",
    "$p(i)$ is vector of preferences for item $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining recommendations\n",
    "\n",
    "If $\\hat{p}_{ui}$, the predicted preference of user $u$ at item $i$, is equal to $y_i^Tx_u$, we can substite our user_factor equation for $x_u$. This gives us:\n",
    "\n",
    "$\\hat{p}_{ui} =  y_i^T(Y^T C^u Y + \\lambda I)^{-1}  Y^T C^u p(u)$\n",
    "\n",
    "Denote $f*f$ matrix $(Y^T C^u Y + \\lambda I)^{-1}$ as $W^u$\n",
    "\n",
    "$W^u$ is considered the weight for user $u$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libaries and utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.whosampled\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import implicit\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import os, sys\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"]=\"1\"\n",
    "\n",
    "import random\n",
    "\n",
    "from src.turn_db_main_into_utility_matrix import from_mongo_collection_to_utility_matrix\n",
    "\n",
    "# Read in the data from the Mongo collection\n",
    "\n",
    "prod_artist, df = from_mongo_collection_to_utility_matrix(db.main_redo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Test/Train Split\n",
    "\n",
    "We can't do the traditional time split for recommendation systems, because the algorithm requires the entire\n",
    "dataframe to train on. Instead, we create a test set by taking some percentage of the actual interactions, and \n",
    "replacing them with zeros- in other words, acting as if the producer has not sampled those artists.\n",
    "\n",
    "We train the model on this `train` dataset with these specific values hidden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_of_test_set_values(ui_util_mat, percent):\n",
    "    \n",
    "    '''\n",
    "    Given a utility matrix and a desired train/test split, returns two lists:\n",
    "    The row and column indices of the test set data.\n",
    "    \n",
    "    Indices should be in user, item form- therefore, matrix needs to be in user_item form.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Get all nonzero inds in our utility matrix. This is two lists of row/pair indices.\n",
    "    nonzero_inds = ui_util_mat.values.nonzero()\n",
    "        \n",
    "    # Turn into list of tuples\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1]))\n",
    "\n",
    "    # Num_samples is percent % of len(interactions)\n",
    "    num_samples = int(np.ceil((percent/100)*len(nonzero_pairs))) \n",
    "    \n",
    "    # Take a % of these as a test set. \n",
    "    samples = random.sample(nonzero_pairs, num_samples) \n",
    "    \n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    \n",
    "    return user_inds, item_inds\n",
    "\n",
    "def make_train_set_and_test_set(user_inds, item_inds, ui_util_mat):\n",
    "    '''\n",
    "    Creates training set with all the values at the test set indices \n",
    "    replaced with zeros.\n",
    "    \n",
    "    Before doing this, copies train set to test set.\n",
    "    '''\n",
    "    train = ui_util_mat.copy()\n",
    "    test = ui_util_mat.copy()\n",
    "    \n",
    "    train.iloc[user_inds, item_inds] = 0\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inds, item_inds = get_indices_of_test_set_values(prod_artist, 10)\n",
    "\n",
    "train, test = make_train_set_and_test_set(user_inds, item_inds, prod_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model on training data \n",
    "\n",
    "The implicit library has a fast implementation of the alternating least squares algorithm, which I use below. \n",
    "\n",
    "The model's fit method expects the sparse utility matrix to be as item/user- however, ours is in user-item.\n",
    "\n",
    "Therefore, the model's item_vecs is our user_vecs, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:04<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_model = implicit.als.AlternatingLeastSquares(factors=100,iterations=15)\n",
    "\n",
    "# train the model on a sparse matrix of user/item/confidence weights\n",
    "sparse_train = csr_matrix(train)\n",
    "train_model.fit(sparse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Model\n",
    "\n",
    "The item factors attribute refers to our user_vectors, since we trained it backwards\n",
    "\n",
    "To explore the recommendations and other attributes, will probably be simplest to retrain the model with a item_user matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16865, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs = train_model.item_factors.shape\n",
    "\n",
    "train_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "We need a metric to evaluate how our model is performing on the test data.\n",
    "### Ranking Algorithm\n",
    "\n",
    "$\\overline{rank} = \\frac{\\sum_{u,i} r^t_{ui} * rank_{ui}}{\\sum_{u,i} r^t_{ui}}$\n",
    "\n",
    "#### where:\n",
    "$r^t_{ui}$ is the # of interactions for observations in the test set, and \n",
    "\n",
    "$rank_{ui}$ are the percentile ranking of each item for each user.\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "We can see that $\\sum_{u,i} r^t_{ui}$ is in both the numerator and the denominator. If $rank_{ui}$ was not in the numerator, $\\overline{rank}$ would simply equal 1. $rank_{ui}$ is the percentile ranking of each item for each user, such that the item most highly recommended has a $rank_{ui}$ of 0.00\\% and the item least recommended has a $rank_{ui}$ of 100.00\\%.\n",
    "\n",
    "Therefore, if the algorithm is correct, the low percentages will cancel out the high $r^t_{ui}$, making the $\\overline{rank}$ go towards 0.\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "1. Get denominator by summing the # of user-item interactions at the test set indices. This is $\\sum_{u,i} r^t_{ui}$, for  $\\overline{rank} = \\frac{\\sum_{u,i} r^t_{ui} * rank_{ui}}{\\sum_{u,i} r^t_{ui}}$   \n",
    "\n",
    "2. Get the $rank_{ui}$ of our model for all $u, i$ in $r^t_{ui}$. This is calculated by getting the predictions of the ALS model, ranking them, taking their percentage, and then selecting only the ones at the selected indices.\n",
    "\n",
    "3. Get rtui \n",
    "\n",
    "4. Multiply $rank_{ui}$ by $r^t_{ui}$ to get numerator. Divide by $rank_{ui}$ to get $\\overline{rank}$\n",
    "\n",
    "5. Use popularity as a baseline for the model. Instead of using the model to rank different songs for artists, the $rank_{ui}$ of popularity for all $u, i$ in $r^t_{ui}$. This is popularity rank score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get denominator by summing the # of user-item interactions at the test set indices. This is $\\sum_{u,i} r^t_{ui}$, for  $\\overline{rank} = \\frac{\\sum_{u,i} r^t_{ui} * rank_{ui}}{\\sum_{u,i} r^t_{ui}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denominator_for_rank_algorithm(user_inds, item_inds, test):\n",
    "    '''\n",
    "    Given a list of row indices, list of column indices, and a test dataset, \n",
    "    sums up the values in the utility matrix at these indices. This is the \n",
    "    denominator of the ranking algorithm.\n",
    "    \n",
    "    It is the r value, in the test set, at indices u, i, summed.\n",
    "    '''\n",
    "    \n",
    "    #Get the denominator value for ranking algorithm.\n",
    "    total_score = []\n",
    "    for i in range(len(user_inds)):\n",
    "\n",
    "        score = test.iloc[user_inds[i], item_inds[i]]\n",
    "        total_score.append(score)\n",
    "    denominator = sum(total_score)\n",
    "    return denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the $rank_{ui}$ of our model for all $u, i$ in $r^t_{ui}$. This is calculated by getting the predictions of the ALS model, ranking them, taking their percentage, and then selecting only the ones at the selected indices.\n",
    "\n",
    "3. Get $r^t_{ui}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_ui(model, user_inds, item_inds):\n",
    "    \n",
    "    '''\n",
    "    Takes a fitted model and calculates the ranking of recommendation for every item\n",
    "    for every user. This is then turned into a percentage.\n",
    "    \n",
    "    Indices refer to the indices of the test set. We thus filter our rankings\n",
    "    to only look at the test set.\n",
    "    '''\n",
    "    \n",
    "    # The model is set to train on item/user/confidence weights. \n",
    "    #But I am training it on user/item.\n",
    "    user_vecs = model.item_factors\n",
    "    item_vecs = model.user_factors\n",
    "    \n",
    "    #predictions is user, items\n",
    "    predictions = user_vecs.dot(item_vecs.T)\n",
    "    \n",
    "    #print(predictions.shape)\n",
    "    #get the rank of each item for each user\n",
    "    #Use axis =1 to sort across, across the artists for each producer.\n",
    "    order = np.flip(predictions.argsort(axis = 1), axis = 1)\n",
    "    ranks = order.argsort(axis = 1)\n",
    "\n",
    "    #turn ranks into percentages\n",
    "    rank_ui = ranks / ranks.shape[0]\n",
    "    \n",
    "    rank_ui = rank_ui[user_inds, item_inds].reshape(-1, 1)\n",
    "    return rank_ui\n",
    "\n",
    "def get_rui(ui_util_mat, user_inds, item_inds):\n",
    "    rui = ui_util_mat.values[user_inds, item_inds].reshape(-1,1)\n",
    "    return rui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Multiply $rank_{ui}$ by $r^t_{ui}$ to get numerator. Divide by $rank_{ui}$ to get $\\overline{rank}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_score(r_ui, rank_ui, denominator):\n",
    "    \n",
    "    '''\n",
    "    Requires r_ui to be in form users, items.\n",
    "    '''\n",
    "    \n",
    "    numerator = r_ui * rank_ui\n",
    "\n",
    "    numer_summation = np.sum(numerator)\n",
    "\n",
    "    rank = numer_summation / denominator\n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to baseline: Just recommend what's popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you just recommend the most popular?\n",
    "\n",
    "# Get most popular items in the mat\n",
    "\n",
    "def get_pop_rank_ui(test, item_inds):\n",
    "    \n",
    "    '''\n",
    "    Returns pop_rank_ui for test data. It counts the samples per artist,\n",
    "    then ranks the artists by their number of samples. \n",
    "    \n",
    "    As before, we only need the percentages for the item_inds\n",
    "    '''\n",
    "    \n",
    "    samples_per_artist = test.sum(axis = 0)\n",
    "    order = np.flip(samples_per_artist.values.argsort(), axis = 0)\n",
    "    ranks = order.argsort()\n",
    "\n",
    "    pop_rank_ui = ranks / len(samples_per_artist)\n",
    "    pop_rank_ui = pop_rank_ui[item_inds].reshape(-1,1)\n",
    "    \n",
    "    return pop_rank_ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = get_denominator_for_rank_algorithm(user_inds, item_inds, test)\n",
    "\n",
    "def model_rank_and_pop_rank_scores(train, test, denominator, user_inds, item_inds, factors):\n",
    "    '''\n",
    "    Takes a train and test set, fits a ALS model to the train set.\n",
    "    Returns rank_scores for the model and popularity(baseline)\n",
    "    '''\n",
    "    \n",
    "    #initialize a new model\n",
    "    train_model = implicit.als.AlternatingLeastSquares(factors=factors,iterations=15)\n",
    "\n",
    "    # train the model on a sparse matrix of user/item/confidence weights\n",
    "    sparse_train = csr_matrix(train)\n",
    "    train_model.fit(sparse_train)\n",
    "\n",
    "    #2\n",
    "    rank_ui = get_rank_ui(train_model, user_inds, item_inds)\n",
    "\n",
    "    #3\n",
    "    rui = get_rui(test, user_inds, item_inds)\n",
    "\n",
    "    #4\n",
    "    rank_score = get_rank_score(rui, rank_ui, denominator)\n",
    "\n",
    "    #5 \n",
    "    pop_rank_ui = get_pop_rank_ui(test, item_inds)\n",
    "    pop_rank_score = get_rank_score(rui, pop_rank_ui, denominator)\n",
    "    \n",
    "    return rank_score, pop_rank_score\n",
    "\n",
    "rank_score, pop_rank_score = model_rank_and_pop_rank_scores(train, test, denominator, user_inds, item_inds, 100)\n",
    "\n",
    "print(\n",
    "\"Model rank score: {} \\n\\\n",
    "Popularity rank score: {}\".format(rank_score, pop_rank_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rank score: 0.2728523843092474 \n",
      "Popularity rank score: 0.09807353651741825\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"Model rank score: {} \\n\\\n",
    "Popularity rank score: {}\".format(rank_score, pop_rank_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "My model does not do as well as popularity unfortunately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing at different # of factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27192606213758064, 0.09807353651741825)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into 2016 after and before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_song_year\n",
       "2019      0.127584\n",
       "2018      1.752243\n",
       "2017      3.614425\n",
       "2016      5.619121\n",
       "2015      8.069004\n",
       "2014     10.856848\n",
       "2013     14.537780\n",
       "2012     18.091127\n",
       "2011     21.231863\n",
       "2010     24.333238\n",
       "2009     26.670467\n",
       "2008     29.158353\n",
       "2007     31.654383\n",
       "2006     34.037759\n",
       "2005     36.783528\n",
       "2004     39.245626\n",
       "2003     41.907244\n",
       "2002     44.100601\n",
       "2001     46.638707\n",
       "2000     49.208030\n",
       "1999     52.375911\n",
       "1998     55.539721\n",
       "1997     58.646525\n",
       "1996     62.246020\n",
       "1995     65.739647\n",
       "1994     70.241731\n",
       "1993     74.872755\n",
       "1992     80.081979\n",
       "1991     84.847374\n",
       "1990     88.833693\n",
       "           ...    \n",
       "1982     98.813741\n",
       "1981     98.892463\n",
       "1980     98.946754\n",
       "1979     99.013261\n",
       "1978     99.082482\n",
       "1977     99.134058\n",
       "1976     99.201922\n",
       "1975     99.280644\n",
       "1974     99.363438\n",
       "1973     99.455732\n",
       "1972     99.523596\n",
       "1971     99.611819\n",
       "1970     99.686469\n",
       "1969     99.771978\n",
       "1968     99.857486\n",
       "1967     99.892775\n",
       "1966     99.929422\n",
       "1965     99.940280\n",
       "1964     99.944352\n",
       "1963     99.951138\n",
       "1962     99.963354\n",
       "1961     99.971497\n",
       "1960     99.980998\n",
       "1959     99.986427\n",
       "1958     99.989142\n",
       "1957     99.990499\n",
       "1956     99.994571\n",
       "1954     99.997285\n",
       "1878     99.998643\n",
       "1863    100.000000\n",
       "Name: URL, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of the data is 2018, 2017, etc?\n",
    "\n",
    "np.cumsum(df.groupby('new_song_year').count()['URL'].apply(\n",
    "    lambda x: (x / len(df)) * 100 ).sort_index(\n",
    "    ascending = False))\n",
    "\n",
    "# If we take the data past 2016-2019 as our test set, we get about 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5945, 18)\n",
      "(67732, 18)\n"
     ]
    }
   ],
   "source": [
    "test = df[df.new_song_year > 2014]\n",
    "train = df[df.new_song_year < 2015]\n",
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1163, 1164, 1163]\n",
      "[544, 544, 544]\n"
     ]
    }
   ],
   "source": [
    "# Songs and users have to be in both, right?\n",
    "\n",
    "#get intersection of sampled_artist and song_producer from train and test set\n",
    "def get_intersection_of_train_and_test_set(train, test, column):\n",
    "    \n",
    "    '''\n",
    "    Takes train and test set and a column, and returns both filtered\n",
    "    to have values they both share\n",
    "    '''\n",
    "    test_column = set(test[column])\n",
    "    train_column = set(train[column])\n",
    "    both_columns = test_column.intersection(train_column)\n",
    "    print([len(test_column), len(train_column), len(both_columns)])\n",
    "    \n",
    "    test = test[test[column].isin(list(both_columns))]\n",
    "\n",
    "    train = train[train[column].isin(list(both_columns))]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train, test = get_intersection_of_train_and_test_set(\n",
    "    train, test, \"sampled_artist\")\n",
    "train, test = get_intersection_of_train_and_test_set(\n",
    "    train, test, \"new_song_producer\")\n",
    "\n",
    "#I needed to run this 3 times to work\n",
    "\n",
    "#I have 1163 artists, and 544 producers shared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_prod_test = pd.crosstab(test_filtered.sampled_artist, columns=test_filtered.new_song_producer )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381, 8653)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_prod_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_prod_train = pd.crosstab(train_filtered.sampled_artist, columns=train_filtered.new_song_producer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:03<00:00,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using the parameters I found to be best from the Grid Search\n",
    "alpha = 20\n",
    "factors = 5\n",
    "iterations = 10\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=200,iterations=15)\n",
    "\n",
    "# training data for the model.\n",
    "sparse_artist_prod = csr_matrix(artist_prod_train)\n",
    "model.fit(sparse_artist_prod)\n",
    "\n",
    "# recommend items for a user\n",
    "# sparse_prod_artist = sparse_artist_prod.T.tocsr()\n",
    "# recommendations = model.recommend(0, sparse_prod_artist, 20, False)\n",
    "\n",
    "# find related items\n",
    "# related = model.similar_items(0, 20)\n",
    "\n",
    "# sim_users = model.similar_users(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = create_rank_ui_from_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (1456, 1381): given (8653, 1381)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-182f78db38bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_rank_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martist_prod_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-07aa5f70de9d>\u001b[0m in \u001b[0;36mreturn_rank_score\u001b[0;34m(percentages, r_ui)\u001b[0m\n\u001b[1;32m     30\u001b[0m     '''\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_ui\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpercentages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mnumer_summation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis)\u001b[0m\n\u001b[1;32m   1974\u001b[0m                                  \u001b[0;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[0;32m-> 1976\u001b[0;31m                                          given_shape=right.shape))\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (1456, 1381): given (8653, 1381)"
     ]
    }
   ],
   "source": [
    "rank = return_rank_score(percentages, artist_prod_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
